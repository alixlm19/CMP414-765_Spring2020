{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color=\"red\">Test I: Wednesday, March 18th 11:00 - 11:45am </font>\n",
    "- Use `numpy` and `pandas` to perform data handling.\n",
    "- Use `sklearn` to train linear regression, polynomial regression, and logistic regression models.\n",
    "- Understand how cost functions measure errors of the predictions.\n",
    "- Understand how normal equation and gradient descent works"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression\n",
    "\n",
    "*Readings: Chapter 4*\n",
    "\n",
    "We have studied how to use linear regression and polynomial regression to *predict a target numeric value*. There is another learning task, **classification**, aiming at predicting group membership rather than numeric values. Email spam filter is a good example: it is trained with many example emails with their class (spam or non-spam), and it must learn how to classify new emails.\n",
    "\n",
    "Linear regression is **not** a good choice for classification tasks. We will introduce the **logistic regression** model and use the iris dataset to illustrate how the model works."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression: Intuition\n",
    "- Picture the data as points on the plane.\n",
    "- A classifier's job is to determine the decision regions for each class.\n",
    "- If a point is far from the decision boundary, then the classifier should be fairly confident about its prediction.\n",
    "- If a point is near the decision boundary, then the classifier may be less confident about its prediction.\n",
    "- The **logistic regression** model aims to provide a **probablity distribution** for each point. The probability distribution has little variance if the point is far from decision boundary.\n",
    "- **Probability distribution with high variance**: rolling a die - there is no way to predict the exact outcome\n",
    "- **Probability distribution with low variance**: getting the flu today - probably not going to happen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://mlr-org.com/docs/2015-07-28-Visualisation-of-predictions_files/figure-html/qda-1.png\" width=\"600\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Binary Classifier\n",
    "- Suppose there are only two classes for the output feature: **Class 0** (the negative class) and **Class 1** (the positive class).\n",
    "- A **binary classifer** tries to estimate the probability $p$ that a point belongs to Class 1.\n",
    "- The probability that a point belongs to Class 0 is $1 - p$.\n",
    "- Given the probability, the binary classifier will compare it with a chosen **threshold** (for example, 0.5), and then predict the class as\n",
    "    - prediction = 1 if $\\hat{p}$ $\\ge$ threshold\n",
    "    - prediction = 0 if $\\hat{p}$ < threshold\n",
    "- The **boundary** of decision regions is given by the curve formed by points whose probability equals to the threshold value."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression: Model Assumption\n",
    "**Binary classifier model**: Logistic regression model assumes that the decision boundary is represented as a linear function:\n",
    "\n",
    "$\\log\\frac{\\hat{p}}{1 - \\hat{p}} = \\theta_0 + \\theta_1x_1 + \\theta_2x_2 +\\cdots + \\theta_nx_n,$\n",
    "- n: number of input features.\n",
    "- $x_1, ..., x_n$: input features\n",
    "- $\\hat{p}$: the estimated probability of data belonging to the class\n",
    "- $\\theta_1,...,\\theta_n$: parameters of the model\n",
    "\n",
    "**Alternative format**:\n",
    "\n",
    "$\\hat{p} = \\sigma(\\textbf{x}\\cdot\\theta^T).$\n",
    "\n",
    "- $\\textbf{x} = (x_1, ..., x_n)$.\n",
    "- $\\theta = (\\theta_1, ..., \\theta_n)$.\n",
    "- $\\sigma(t) = \\frac{1}{1+e^{-t}}$: logistic function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the graph of logistic function\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression: Decision Rule\n",
    "\n",
    "**Decision rule**: Pick a threshold (for example, 0.5), and then\n",
    "\n",
    "- prediction = 1 if $\\hat{p}$ $\\ge$ threshold\n",
    "- prediction = 0 if $\\hat{p}$ < threshold\n",
    "\n",
    "**Trade-off with threshold**:\n",
    "- If threshold is chosen closer to 1, then the positive predictions are __more likely__ to be correct (fewer **false positives**). However, the negative predictions are __less likely__ to be correct.\n",
    "- If threshold is chosen closer to 0, then the negative predictions are __more likely__ to be correct (fewer **false negatives**). However, the positive predictions are __less likely__ to be correct."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://hackernoon.com/hn-images/1*YV7zy1NGN1-HGQxY56nc_Q.png\" width=\"600\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression Example: The Iris Dataset\n",
    "\n",
    "**Iris dataset** is a famous dataset that contains the sepal and petal length and width of 150 iris flowers of three different species: Iris-Setosa, Iris-Versicolor, and Iris-Virginica. [wiki page](https://en.wikipedia.org/wiki/Iris_flower_data_set)\n",
    "\n",
    "- Import dataset using <code>sklearn.dataset.load_iris()</code>\n",
    "- Explore the dataset: data description, feature names, data types, data histograms, scatter plots.\n",
    "- Split the dataset into train_set and test_set\n",
    "- Apply <code>sklearn.linear_model.LogisticRegression</code> to build a binary classifier on **Iris-Virginica**.\n",
    "- Evaluate the performance of the model: Accuracy, cross-validation, precision vs. recall, confusion matrix...\n",
    "- Visualize the model (show decision boundary)\n",
    "\n",
    "<img src=\"https://lh3.googleusercontent.com/proxy/kGs0Y8tElhGYuH6BUpxNg4F14JsepyVrrWUfMoN-uUKaJh-V3AUHsWI6b4zBTy3z-ipCrXMG8IRQxaiIRyxMfSU\" width=\"600\">\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "from sklearn import datasets\n",
    "iris = datasets.load_iris()\n",
    "\n",
    "iris.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Explore the dataset\n",
    "print(iris['DESCR'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(iris['feature_names'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Convert the data into a data frame\n",
    "iris_df = pd.DataFrame(data=iris['data'], columns=iris['feature_names'])\n",
    "iris_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Add the target class\n",
    "# print(iris['target'])\n",
    "iris_df['target'] = iris['target']\n",
    "iris_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "iris['target_names']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a function that maps 0-2 to the actual type of iris\n",
    "def get_target_name(x):\n",
    "    return iris['target_names'][x]\n",
    "\n",
    "x = iris_df.loc[0, 'target']\n",
    "name = get_target_name(x)\n",
    "print(x, name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply get_target_name() to all target values\n",
    "iris_df['target_name'] = iris_df['target'].apply(get_target_name)\n",
    "iris_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Draw scatter plots.\n",
    "# scatter plot: sepal length vs. sepal width\n",
    "plt.scatter(iris_df.iloc[:, 0], iris_df.iloc[:, 1], c=iris_df['target'])\n",
    "plt.xlabel(\"sepal length\")\n",
    "plt.ylabel(\"sepal width\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Draw all scatter plots\n",
    "from pandas.plotting import scatter_matrix\n",
    "scatter_matrix(iris_df.iloc[:, :4], figsize=(15, 15), marker='x',\n",
    "               c=iris_df['target'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build A Binary Classifier for Iris-Virginica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function is_virginica(target) that returns 1 if target is Virginica, and 0 otherwise\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply function is_virginica() to the data frame, creating a new column \"Is_Virginica\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train-test split\n",
    "# Split the data frame into 85% training data and 15% test data\n",
    "from sklearn.model_selection import train_test_split\n",
    "df_train, df_test = \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Display the amount of Virginica and non-Virginica cases in the training set\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the logistic regression model\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Evaluation\n",
    "- Classification accuracy\n",
    "- Cross Validation\n",
    "- Examine four categories using the confusion matrix:\n",
    "    - True Positive\n",
    "    - True Negative\n",
    "    - False Positive\n",
    "    - False Negative\n",
    "- Precision, recall, and F1 score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Find the prediction accuracy on test set\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. cross validation\n",
    "from sklearn.model_selection import cross_val_score\n",
    "input_cols = iris_df.columns[:4]\n",
    "print(cross_val_score(model, df_train[input_cols], df_train['is_virginica'],\n",
    "                      cv=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 3. confusion matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "matrix = confusion_matrix(df_test['is_virginica'], test_predictions)\n",
    "plt.matshow(matrix)\n",
    "print(matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Precision and Recall\n",
    "<img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/2/26/Precisionrecall.svg/525px-Precisionrecall.svg.png\" width=\"600\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# precision - recall - f1 score\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred = model2.predict(X)\n",
    "Y_pred_prob = model2.predict_proba(X)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Logistic Regression: Model Visualization\n",
    "- Create a grid of points from a list of x coordinates and y coordinates.\n",
    "- Use the model to obtain prediction probability on each point from the grid\n",
    "- Find points with marginal probabilities.\n",
    "- Plot the grid."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Train a new logistic regression model on petal length and petal width only\n",
    "model = LogisticRegression(solver='lbfgs')\n",
    "model.fit(df_train['petal length (cm)', 'petal width (cm)'], df_train['is_virginica'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Create a grid of points\n",
    "x0, x1 = np.meshgrid(np.linspace(0, 7, 500),\n",
    "                     np.linspace(0, 2.7, 500))\n",
    "print(x0.shape, x1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Obtain prediction probabilities\n",
    "X_new = np.hstack([x0.reshape([-1, 1]), x1.reshape([-1, 1])])\n",
    "y_new_prob = model.predict_proba(X_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Find boundary points.\n",
    "# Which points give 0.5 probability?\n",
    "indices = np.where((y_new_prob[:, 1] > 0.499) & (y_new_prob[:, 1] < 0.501))\n",
    "X_boundary = X_new[indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Plot the boundary\n",
    "plt.plot(X_boundary[:, 0], X_boundary[:, 1])\n",
    "index_virginica = (iris_df['is_virginica'] == 1)\n",
    "index_not_virginica = (iris_df['is_virginica'] == 0)\n",
    "plt.scatter(iris_df.loc[index_virginica, 'petal length (cm)'],\n",
    "            iris_df.loc[index_virginica, 'petal width (cm)'],\n",
    "            c='yellow',\n",
    "            label='Virginica')\n",
    "plt.scatter(iris_df.loc[index_not_virginica, 'petal length (cm)'],\n",
    "            iris_df.loc[index_not_virginica, 'petal width (cm)'],\n",
    "            c='purple',\n",
    "            label='Not Virginica')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Plot probabilities\n",
    "plt.scatter(X_new[:, 0], X_new[:, 1], c=y_new_prob[:, 0])\n",
    "plt.colorbar()\n",
    "plt.scatter(iris_df.loc[index_virginica, 'petal length (cm)'],\n",
    "            iris_df.loc[index_virginica, 'petal width (cm)'],\n",
    "            c='yellow',\n",
    "            label='Virginica')\n",
    "plt.scatter(iris_df.loc[index_not_virginica, 'petal length (cm)'],\n",
    "            iris_df.loc[index_not_virginica, 'petal width (cm)'],\n",
    "            c='purple',\n",
    "            label='Not Virginica')\n",
    "plt.legend()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
